{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"executionInfo":{"elapsed":3821,"status":"ok","timestamp":1733043184414,"user":{"displayName":"Fajar Aulia M247B4KY1372","userId":"14465906709521728749"},"user_tz":-480},"id":"ax5doCT4HdXK"},"outputs":[],"source":["import os\n","import random\n","import gdown\n","import tensorflow as tf\n","from tensorflow import keras\n","\n","INPUT_SIZE = (224, 224)\n","CUSTOM_MODEL_NAME = 'custom-mobnet-pretrained'\n","\n","WORKING_PATHS = {\n","    'BASE': os.path.join('workspace'),\n","    'DATASET': os.path.join('workspace', 'dataset'),\n","    'TRAIN_DATASET': os.path.join('workspace', 'dataset', 'train'),\n","    'TEST_DATASET': os.path.join('workspace', 'dataset', 'test'),\n","    'OUTPUT': os.path.join('workspace', 'output'),\n","    'EXPORT': os.path.join('workspace', 'output', CUSTOM_MODEL_NAME, 'export', 'hand-sign-bisindo'),\n","    'TFLITE':os.path.join('workspace', 'output', CUSTOM_MODEL_NAME, 'tfliteexport'),\n","    'JSON':os.path.join('workspace', 'output', CUSTOM_MODEL_NAME, 'json'),\n"," }"]},{"cell_type":"code","execution_count":2,"metadata":{"executionInfo":{"elapsed":1263,"status":"ok","timestamp":1733043185672,"user":{"displayName":"Fajar Aulia M247B4KY1372","userId":"14465906709521728749"},"user_tz":-480},"id":"vdR-O4UTHdXL"},"outputs":[],"source":["# Create working dirs\n","for path in WORKING_PATHS.values():\n","    if not os.path.exists(path):\n","        if os.name == 'posix':\n","            !mkdir -p {path}\n","        if os.name == 'nt':\n","            !mkdir {path}"]},{"cell_type":"code","execution_count":3,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"IlL6ZCCIZ0w7","executionInfo":{"status":"ok","timestamp":1733043185672,"user_tz":-480,"elapsed":15,"user":{"displayName":"Fajar Aulia M247B4KY1372","userId":"14465906709521728749"}},"outputId":"7d2ac4ca-95b5-42ab-ef92-c2053c942a44"},"outputs":[{"output_type":"stream","name":"stdout","text":["Training labels: []\n","Testing labels: []\n"]}],"source":["print(\"Training labels:\", os.listdir(WORKING_PATHS['TRAIN_DATASET']))\n","print(\"Testing labels:\", os.listdir(WORKING_PATHS['TEST_DATASET']))"]},{"cell_type":"code","execution_count":4,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":334},"executionInfo":{"elapsed":683,"status":"ok","timestamp":1733043186345,"user":{"displayName":"Fajar Aulia M247B4KY1372","userId":"14465906709521728749"},"user_tz":-480},"id":"4FxtA-Q0HdXO","outputId":"8de1bdd1-97af-497f-eef3-9fa275effdf5"},"outputs":[{"output_type":"stream","name":"stderr","text":["WARNING:matplotlib.legend:No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n","WARNING:matplotlib.legend:No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n"]},{"output_type":"display_data","data":{"text/plain":["<Figure size 1000x300 with 2 Axes>"],"image/png":"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\n"},"metadata":{}}],"source":["# Check total dataset each labels\n","import numpy as np\n","import matplotlib.pyplot as plt\n","\n","static_labels = os.listdir(WORKING_PATHS['TRAIN_DATASET'])\n","TRAIN_IMG_MIN = 9999\n","train_data_num = {}\n","test_data_num = {}\n","\n","for label in static_labels:\n","    train_data_num[label] = len(os.listdir(os.path.join(WORKING_PATHS['TRAIN_DATASET'], label)))\n","    test_data_num[label] = len(os.listdir(os.path.join(WORKING_PATHS['TEST_DATASET'], label)))\n","    if train_data_num[label] < TRAIN_IMG_MIN:\n","        TRAIN_IMG_MIN = train_data_num[label]\n","\n","y_pos = np.arange(len(static_labels))\n","train_values = train_data_num.values()\n","test_values = test_data_num.values()\n","\n","fig, axs = plt.subplots(1, 2, figsize = (10, 3))\n","fig.suptitle('Training and Validation plotting')\n","axs[0].bar(y_pos, train_values, align = 'center', alpha = 0.5)\n","axs[0].set_xticks(y_pos, static_labels)\n","axs[0].set_title('Training')\n","axs[0].legend()\n","axs[1].bar(y_pos, test_values, align = 'center', alpha = 0.5)\n","axs[1].set_xticks(y_pos, static_labels)\n","axs[1].set_title('Testing')\n","axs[1].legend()\n","\n","plt.show()"]},{"cell_type":"code","execution_count":5,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":388},"executionInfo":{"elapsed":22,"status":"error","timestamp":1733043186346,"user":{"displayName":"Fajar Aulia M247B4KY1372","userId":"14465906709521728749"},"user_tz":-480},"id":"frX9kErIHdXR","outputId":"d7d16dc3-b0fd-4518-8ee8-c7da0dae6e67"},"outputs":[{"output_type":"error","ename":"ValueError","evalue":"Number of rows must be a positive integer, not 0","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)","\u001b[0;32m<ipython-input-5-07eb810df9a6>\u001b[0m in \u001b[0;36m<cell line: 15>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;31m# Show image plot\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0mfig_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m \u001b[0mfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msubplots\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrows\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcols\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfigsize\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfig_size\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mcols\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mfig_size\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mrows\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m \u001b[0mfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msuptitle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Random Selected Trainning Preview'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0mfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtight_layout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/matplotlib/pyplot.py\u001b[0m in \u001b[0;36msubplots\u001b[0;34m(nrows, ncols, sharex, sharey, squeeze, width_ratios, height_ratios, subplot_kw, gridspec_kw, **fig_kw)\u001b[0m\n\u001b[1;32m   1597\u001b[0m     \"\"\"\n\u001b[1;32m   1598\u001b[0m     \u001b[0mfig\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfigure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mfig_kw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1599\u001b[0;31m     axs = fig.subplots(nrows=nrows, ncols=ncols, sharex=sharex, sharey=sharey,\n\u001b[0m\u001b[1;32m   1600\u001b[0m                        \u001b[0msqueeze\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msubplot_kw\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msubplot_kw\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1601\u001b[0m                        \u001b[0mgridspec_kw\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mgridspec_kw\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mheight_ratios\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mheight_ratios\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/matplotlib/figure.py\u001b[0m in \u001b[0;36msubplots\u001b[0;34m(self, nrows, ncols, sharex, sharey, squeeze, width_ratios, height_ratios, subplot_kw, gridspec_kw)\u001b[0m\n\u001b[1;32m    928\u001b[0m             \u001b[0mgridspec_kw\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'width_ratios'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwidth_ratios\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    929\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 930\u001b[0;31m         \u001b[0mgs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_gridspec\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnrows\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mncols\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfigure\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mgridspec_kw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    931\u001b[0m         axs = gs.subplots(sharex=sharex, sharey=sharey, squeeze=squeeze,\n\u001b[1;32m    932\u001b[0m                           subplot_kw=subplot_kw)\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/matplotlib/figure.py\u001b[0m in \u001b[0;36madd_gridspec\u001b[0;34m(self, nrows, ncols, **kwargs)\u001b[0m\n\u001b[1;32m   1540\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1541\u001b[0m         \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'figure'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pop in case user has added this...\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1542\u001b[0;31m         \u001b[0mgs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mGridSpec\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnrows\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnrows\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mncols\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mncols\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfigure\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1543\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mgs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1544\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/matplotlib/gridspec.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, nrows, ncols, figure, left, bottom, right, top, wspace, hspace, width_ratios, height_ratios)\u001b[0m\n\u001b[1;32m    376\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfigure\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfigure\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    377\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 378\u001b[0;31m         super().__init__(nrows, ncols,\n\u001b[0m\u001b[1;32m    379\u001b[0m                          \u001b[0mwidth_ratios\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mwidth_ratios\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    380\u001b[0m                          height_ratios=height_ratios)\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/matplotlib/gridspec.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, nrows, ncols, height_ratios, width_ratios)\u001b[0m\n\u001b[1;32m     46\u001b[0m         \"\"\"\n\u001b[1;32m     47\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnrows\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mIntegral\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mnrows\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 48\u001b[0;31m             raise ValueError(\n\u001b[0m\u001b[1;32m     49\u001b[0m                 f\"Number of rows must be a positive integer, not {nrows!r}\")\n\u001b[1;32m     50\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mncols\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mIntegral\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mncols\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mValueError\u001b[0m: Number of rows must be a positive integer, not 0"]},{"output_type":"display_data","data":{"text/plain":["<Figure size 900x0 with 0 Axes>"]},"metadata":{}}],"source":["# Requirement Lib Import\n","import math\n","from tensorflow.keras.preprocessing import image\n","import matplotlib.pyplot as plt\n","\n","# Random seed\n","seed = random.randint(0, TRAIN_IMG_MIN)\n","\n","# plot matrix size\n","cols = 3\n","rows = math.ceil(len(static_labels) / 3)\n","\n","# Show image plot\n","fig_size = 3\n","fig, axs = plt.subplots(rows, cols, figsize = ((fig_size * cols), (fig_size * rows)))\n","fig.suptitle('Random Selected Trainning Preview')\n","fig.tight_layout()\n","fig.subplots_adjust(top = 0.95)\n","axs = axs.ravel()\n","\n","# Image training random selector\n","img_dict = {}\n","for idx, label in enumerate(static_labels):\n","    img_path = os.path.join(WORKING_PATHS['TRAIN_DATASET'], label)\n","    img_rand = os.listdir(img_path)[seed]\n","    img_selc = image.load_img(os.path.join(img_path, img_rand))\n","\n","    axs[idx].imshow(img_selc.resize(INPUT_SIZE))\n","    axs[idx].set_title(label)"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":19,"status":"aborted","timestamp":1733043186346,"user":{"displayName":"Fajar Aulia M247B4KY1372","userId":"14465906709521728749"},"user_tz":-480},"id":"Nb4pJP2jHdXS"},"outputs":[],"source":["# Dataset pre-processing\n","from tensorflow.keras.preprocessing.image import ImageDataGenerator\n","\n","train_datagen = ImageDataGenerator(\n","    rescale = 1 / 255,\n","    rotation_range = 10,\n","    width_shift_range = 0.2,\n","    height_shift_range = 0.2,\n","    shear_range = 0.2,\n","    zoom_range = 0.2,\n","    horizontal_flip = True,\n","    fill_mode = 'nearest'\n",")\n","validation_datagen = ImageDataGenerator(rescale = 1 / 255)\n","\n","train_generator = train_datagen.flow_from_directory(\n","    WORKING_PATHS['TRAIN_DATASET'],\n","    target_size = INPUT_SIZE,\n","    class_mode = 'categorical'\n",")\n","validation_generator = validation_datagen.flow_from_directory(\n","    WORKING_PATHS['TEST_DATASET'],\n","    target_size = INPUT_SIZE,\n","    class_mode = 'categorical'\n",")"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":18,"status":"aborted","timestamp":1733043186346,"user":{"displayName":"Fajar Aulia M247B4KY1372","userId":"14465906709521728749"},"user_tz":-480},"id":"2RiHeezWHdXT"},"outputs":[],"source":["# defined classes based on foldering structure, sort by alphabetical\n","LABELS = list(train_generator.class_indices.keys())\n","NUM_CLASSES = len(LABELS) # Set classes num\n","print(NUM_CLASSES)"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":19,"status":"aborted","timestamp":1733043186347,"user":{"displayName":"Fajar Aulia M247B4KY1372","userId":"14465906709521728749"},"user_tz":-480},"id":"53Y44VlpHdXT"},"outputs":[],"source":["class EarlyStoppingAtGivenAccuracy(keras.callbacks.Callback):\n","    \"\"\"\n","        Stop training when the accuracy at given threshold\n","    \"\"\"\n","    def __init__(self, threshold = 0.9):\n","        super(EarlyStoppingAtGivenAccuracy, self).__init__()\n","        self.threshold = threshold\n","\n","    def on_epoch_end(self, epoch, logs = None):\n","        logs = logs or {}\n","        acc = logs.get('accuracy')\n","        if acc is not None:\n","            if acc >= self.threshold:\n","                print('Epoch {}: Reached baseline, stop training'.format(epoch))\n","                self.model.stop_training = True\n","\n","from tensorflow.keras.callbacks import Callback\n","\n","class EarlyStoppingAtSeparateThresholds(Callback):\n","    \"\"\"\n","    Stop training when training accuracy and validation accuracy\n","    each reach their respective thresholds.\n","    \"\"\"\n","    def __init__(self, train_threshold=0.9, val_threshold=0.85):\n","        super(EarlyStoppingAtSeparateThresholds, self).__init__()\n","        self.train_threshold = train_threshold\n","        self.val_threshold = val_threshold\n","\n","    def on_epoch_end(self, epoch, logs=None):\n","        logs = logs or {}\n","        train_acc = logs.get('accuracy')\n","        val_acc = logs.get('val_accuracy')\n","\n","        # Check if training accuracy and validation accuracy reach their respective thresholds\n","        if train_acc is not None and val_acc is not None:\n","            if train_acc >= self.train_threshold and val_acc >= self.val_threshold:\n","                print(\n","                    f\"Epoch {epoch}: Training accuracy reached {train_acc:.4f} (threshold: {self.train_threshold}) \"\n","                    f\"and validation accuracy reached {val_acc:.4f} (threshold: {self.val_threshold}), stopping training.\"\n","                )\n","                self.model.stop_training = True\n"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":19,"status":"aborted","timestamp":1733043186347,"user":{"displayName":"Fajar Aulia M247B4KY1372","userId":"14465906709521728749"},"user_tz":-480},"id":"aqQJlHx1HdXU"},"outputs":[],"source":["# from tensorflow.keras.applications import MobileNetV3Small\n","from tensorflow.keras.applications import MobileNetV2\n","\n","pre_trained_model = MobileNetV2(\n","    weights = 'imagenet',\n","    input_shape = (INPUT_SIZE[0], INPUT_SIZE[1], 3),\n","    include_top = False,\n",")\n","\n","pre_trained_model.trainable = False"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":18,"status":"aborted","timestamp":1733043186347,"user":{"displayName":"Fajar Aulia M247B4KY1372","userId":"14465906709521728749"},"user_tz":-480},"id":"jWtg5P8wHdXV","tags":[]},"outputs":[],"source":["# Fine Tuning\n","pre_trained_model.trainable = True\n","\n","for layer in pre_trained_model.layers[:100]:\n","    layer.trainable = False"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":18,"status":"aborted","timestamp":1733043186347,"user":{"displayName":"Fajar Aulia M247B4KY1372","userId":"14465906709521728749"},"user_tz":-480},"id":"dUAQjPtFHdXW"},"outputs":[],"source":["from tensorflow.keras import layers\n","from tensorflow.keras import Model\n","from tensorflow.keras.optimizers import Adam\n","\n","\n","x = layers.Flatten()(pre_trained_model.output)\n","\n","x = layers.Dense(512, activation = 'relu')(x)\n","\n","x = layers.Dropout(0.1)(x)\n","\n","x = layers.Dense(NUM_CLASSES, activation = 'softmax')(x)\n","\n","model = Model(inputs = pre_trained_model.input, outputs = x)\n","\n","model = tf.keras.Sequential([\n","    pre_trained_model,\n","    tf.keras.layers.Flatten(),\n","    tf.keras.layers.Dropout(0.2),\n","    tf.keras.layers.Dense(512, activation = 'relu'),\n","    tf.keras.layers.Dense(NUM_CLASSES, activation = 'softmax')\n","])\n","\n","model.compile(\n","    optimizer = Adam(learning_rate = 0.0001),\n","    loss = 'categorical_crossentropy',\n","    metrics = ['accuracy']\n",")\n","\n","# callback = EarlyStoppingAtGivenAccuracy(0.97)\n","history = model.fit(\n","    train_generator,\n","    validation_data = validation_generator,\n","    epochs = 30,\n","    validation_steps = 5,\n","    verbose = 1,\n","    # callbacks = [callback]\n",")"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":18,"status":"aborted","timestamp":1733043186347,"user":{"displayName":"Fajar Aulia M247B4KY1372","userId":"14465906709521728749"},"user_tz":-480},"id":"obqKc1Z3HdXW"},"outputs":[],"source":["acc = history.history['accuracy']\n","val_acc = history.history['val_accuracy']\n","loss = history.history['loss']\n","val_loss = history.history['val_loss']\n","\n","epochs = range(len(acc))\n","\n","fig, axs = plt.subplots(2, 1, figsize = (5, 6))\n","fig.suptitle('Training and Validation plotting')\n","axs[0].plot(epochs, acc, 'r', label = 'Training accuracy')\n","axs[0].plot(epochs, val_acc, 'b', label = 'Validation accuracy')\n","axs[0].set_title('Training')\n","axs[0].legend()\n","axs[1].plot(epochs, loss, 'r', label = 'Training Loss')\n","axs[1].plot(epochs, val_loss, 'b', label = 'Validation Loss')\n","axs[1].set_title('Loss')\n","axs[1].legend()\n","plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":17,"status":"aborted","timestamp":1733043186347,"user":{"displayName":"Fajar Aulia M247B4KY1372","userId":"14465906709521728749"},"user_tz":-480},"id":"WQfmpNSjHdXX"},"outputs":[],"source":["from tensorflow.keras.optimizers import Adam\n","\n","model.compile(\n","    optimizer = Adam(learning_rate = 0.000001),\n","    loss = 'categorical_crossentropy',\n","    metrics = ['accuracy']\n",")\n","\n","# Start Training!\n","callback = EarlyStoppingAtSeparateThresholds(train_threshold=0.99, val_threshold=0.95)\n","history2 = model.fit(\n","    train_generator,\n","    validation_data = validation_generator,\n","    initial_epoch = 30,\n","    epochs = 60,\n","    validation_steps = 5,\n","    verbose = 1,\n","    callbacks = [callback]\n",")"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":17,"status":"aborted","timestamp":1733043186347,"user":{"displayName":"Fajar Aulia M247B4KY1372","userId":"14465906709521728749"},"user_tz":-480},"id":"_f0IyDOXHdXX"},"outputs":[],"source":["acc = history.history['accuracy']\n","val_acc = history.history['val_accuracy']\n","loss = history.history['loss']\n","val_loss = history.history['val_loss']\n","\n","acc2 = history2.history['accuracy']\n","val_acc2 = history2.history['val_accuracy']\n","loss2 = history2.history['loss']\n","val_loss2 = history2.history['val_loss']\n","\n","epochs = range(len(acc) + len(acc2))\n","\n","fig, axs = plt.subplots(2, 1, figsize = (10, 6))\n","fig.suptitle('Training and Validation plotting')\n","axs[0].plot(epochs, acc + acc2, 'r', label = 'Training accuracy')\n","axs[0].plot(epochs, val_acc + val_acc2, 'b', label = 'Validation Training accuracy')\n","axs[0].set_title('Training')\n","axs[0].legend()\n","axs[0].axvline(x = len(acc))\n","axs[1].plot(epochs, loss + loss2, 'r', label = 'Loss accuracy')\n","axs[1].plot(epochs, val_loss + val_loss2, 'b', label = 'Validation Loss accuracy')\n","axs[1].set_title('Loss')\n","axs[1].legend()\n","axs[1].axvline(x = len(acc))\n","plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"P8nxcYzjZ0xH","executionInfo":{"status":"aborted","timestamp":1733043186347,"user_tz":-480,"elapsed":17,"user":{"displayName":"Fajar Aulia M247B4KY1372","userId":"14465906709521728749"}}},"outputs":[],"source":["from tensorflow.keras.callbacks import Callback\n","\n","class CustomCallback(Callback):\n","    def __init__(self, target_accuracy=0.98, max_val_loss=0.17):\n","        super().__init__()\n","        self.target_accuracy = target_accuracy\n","        self.max_val_loss = max_val_loss\n","\n","    def on_epoch_end(self, epoch, logs=None):\n","        # Memeriksa apakah accuracy >= 0.95 dan validation loss <= 0.1\n","        val_loss = logs.get('val_loss')\n","        accuracy = logs.get('accuracy')\n","\n","        if accuracy >= self.target_accuracy and val_loss <= self.max_val_loss:\n","            print(f\"\\nEpoch {epoch+1}: Accuracy is {accuracy:.4f} and validation loss is {val_loss:.4f}. Stopping training.\")\n","            self.model.stop_training = True  # Menghentikan pelatihan"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"CzUsMdbaZ0xH","executionInfo":{"status":"aborted","timestamp":1733043186348,"user_tz":-480,"elapsed":18,"user":{"displayName":"Fajar Aulia M247B4KY1372","userId":"14465906709521728749"}}},"outputs":[],"source":["from tensorflow.keras.optimizers import Adam\n","\n","model.compile(\n","    optimizer = Adam(learning_rate = 0.000001),\n","    loss = 'categorical_crossentropy',\n","    metrics = ['accuracy']\n",")\n","\n","# callback = EarlyStoppingAtSeparateThresholds(train_threshold=0.99, val_threshold=0.95)\n","custom_callback = CustomCallback(target_accuracy=0.98, max_val_loss=0.17)\n","history2 = model.fit(\n","    train_generator,\n","    validation_data = validation_generator,\n","    initial_epoch = 60,\n","    epochs = 90,\n","    validation_steps = 5,\n","    verbose = 1,\n","    callbacks = [custom_callback]\n",")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"xztJSEFKZ0xI","executionInfo":{"status":"aborted","timestamp":1733043186348,"user_tz":-480,"elapsed":17,"user":{"displayName":"Fajar Aulia M247B4KY1372","userId":"14465906709521728749"}}},"outputs":[],"source":["acc = history.history['accuracy']\n","val_acc = history.history['val_accuracy']\n","loss = history.history['loss']\n","val_loss = history.history['val_loss']\n","\n","acc2 = history2.history['accuracy']\n","val_acc2 = history2.history['val_accuracy']\n","loss2 = history2.history['loss']\n","val_loss2 = history2.history['val_loss']\n","\n","epochs = range(len(acc) + len(acc2))\n","\n","fig, axs = plt.subplots(2, 1, figsize = (10, 6))\n","fig.suptitle('Training and Validation plotting')\n","axs[0].plot(epochs, acc + acc2, 'r', label = 'Training accuracy')\n","axs[0].plot(epochs, val_acc + val_acc2, 'b', label = 'Validation Training accuracy')\n","axs[0].set_title('Training')\n","axs[0].legend()\n","axs[0].axvline(x = len(acc))\n","axs[1].plot(epochs, loss + loss2, 'r', label = 'Loss accuracy')\n","axs[1].plot(epochs, val_loss + val_loss2, 'b', label = 'Validation Loss accuracy')\n","axs[1].set_title('Loss')\n","axs[1].legend()\n","axs[1].axvline(x = len(acc))\n","plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":17,"status":"aborted","timestamp":1733043186348,"user":{"displayName":"Fajar Aulia M247B4KY1372","userId":"14465906709521728749"},"user_tz":-480},"id":"H7M2pWeMHdXY"},"outputs":[],"source":["def selectRandomImage(labels = None):\n","    if labels == None:\n","        seed = random.randint(1, NUM_CLASSES)\n","        label_seed = LABELS[seed - 1]\n","    else:\n","        seed = random.randint(1, len(labels))\n","        label_seed = labels[seed - 1]\n","\n","    path = os.path.join(WORKING_PATHS['TRAIN_DATASET'], label_seed)\n","    test_dir = os.listdir(path)\n","    test_dir_num = len(test_dir)\n","    file_name = os.listdir(path)[random.randint(0, test_dir_num - 1)]\n","    return (os.path.join(path, file_name), file_name, label_seed)"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":17,"status":"aborted","timestamp":1733043186348,"user":{"displayName":"Fajar Aulia M247B4KY1372","userId":"14465906709521728749"},"user_tz":-480},"id":"PKmvLw4HHdXY"},"outputs":[],"source":["def createResultPlot(prediction_list, prediction_label, actual_label, file_name):\n","    # Result Plot\n","    fig, axs = plt.subplots(1, 2, figsize = (10, 5))\n","    fig.suptitle('Image {} predict as: {}'.format(file_name, prediction_label))\n","    fig.subplots_adjust(top = 2)\n","    fig.tight_layout()\n","    axs = axs.ravel()\n","\n","    if prediction_label == actual_label:\n","        fig.patch.set_facecolor('xkcd:mint green')\n","    else:\n","        fig.patch.set_facecolor('xkcd:pale pink')\n","\n","    axs[0].set_title(actual_label)\n","    axs[0].imshow(img)\n","\n","    axs[1].set_title('Probabilities')\n","    axs[1].bar(range(0, NUM_CLASSES), prediction_list, align = 'center')\n","    axs[1].set_xticks(range(0, NUM_CLASSES))\n","    axs[1].set_xticklabels(LABELS)\n","\n","    plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":16,"status":"aborted","timestamp":1733043186348,"user":{"displayName":"Fajar Aulia M247B4KY1372","userId":"14465906709521728749"},"user_tz":-480},"id":"hP_4XA4VHdXZ"},"outputs":[],"source":["import numpy as np\n","import matplotlib.pyplot as plt\n","from tensorflow.keras.preprocessing import image\n","from tensorflow.keras.applications.mobilenet_v2 import preprocess_input\n","\n","\n","# file_path, file_name, label = selectRandomImage()\n","file_path, file_name, label = selectRandomImage(['Y'])\n","img = image.load_img(file_path, target_size = INPUT_SIZE)\n","x = image.img_to_array(img)\n","x = np.expand_dims(x, axis = 0)\n","x = preprocess_input(x)\n","\n","prediction = model.predict(x, batch_size = 10)\n","index = int(prediction[0].argmax(axis = -1))\n","\n","createResultPlot(prediction[0].reshape(NUM_CLASSES), LABELS[index], label, file_name)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"BTTVA_jqZ0xM","executionInfo":{"status":"aborted","timestamp":1733043186348,"user_tz":-480,"elapsed":16,"user":{"displayName":"Fajar Aulia M247B4KY1372","userId":"14465906709521728749"}}},"outputs":[],"source":["pip uninstall numpy"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"WWebegTyHdXZ","scrolled":true,"executionInfo":{"status":"aborted","timestamp":1733043186348,"user_tz":-480,"elapsed":16,"user":{"displayName":"Fajar Aulia M247B4KY1372","userId":"14465906709521728749"}}},"outputs":[],"source":["import numpy as np\n","import matplotlib.pyplot as plt\n","from tensorflow.keras.preprocessing import image\n","from tensorflow.keras.applications.mobilenet_v2 import preprocess_input\n","from sklearn.metrics import confusion_matrix\n","\n","y_true = []\n","y_pred = []\n","\n","for label in LABELS:\n","    path = os.path.join(WORKING_PATHS['TEST_DATASET'], label)\n","    files = os.listdir(path)\n","    for idx, file_name in enumerate(files):\n","        file_loc = os.path.join(path, file_name)\n","        img = image.load_img(file_loc, target_size = INPUT_SIZE)\n","        x = image.img_to_array(img)\n","        x = np.expand_dims(x, axis = 0)\n","        x = preprocess_input(x)\n","\n","        prediction = model.predict(x, batch_size = 10)\n","        index = int(prediction[0].argmax(axis = -1))\n","        y_true.append(label)\n","        y_pred.append(LABELS[index])\n","        # print('Image with label {} predicted as {}'.format(label, LABELS[index]))\n","\n","mat = confusion_matrix(y_true, y_pred, labels = LABELS)\n","\n","mat_norm = mat / mat.astype(np.float64).sum(axis = 1)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"yWJlfZLqZ0xN","executionInfo":{"status":"aborted","timestamp":1733043186348,"user_tz":-480,"elapsed":15,"user":{"displayName":"Fajar Aulia M247B4KY1372","userId":"14465906709521728749"}}},"outputs":[],"source":["import seaborn as sn\n","import pandas as pd\n","import matplotlib.pyplot as plt\n","\n","# Buat DataFrame confusion matrix\n","df_cm = pd.DataFrame(mat_norm, index=LABELS, columns=LABELS)\n","\n","# Perbesar ukuran gambar dan sesuaikan parameter\n","plt.figure(figsize=(20, 15))  # Perbesar ukuran lebih besar\n","ax = sn.heatmap(\n","    df_cm,\n","    annot=True,\n","    fmt=\".2f\",  # Format angka di setiap sel\n","    cmap=\"coolwarm\",  # Gunakan colormap yang kontras\n","    annot_kws={\"size\": 10},  # Ukuran anotasi diperbesar\n","    linewidths=0.5,  # Tambahkan garis antar sel\n","    linecolor=\"black\"  # Warna garis antar sel\n",")\n","\n","# Set judul dan label\n","ax.set_title(\"Test Confusion Matrix\", fontsize=20, pad=20)\n","ax.set_xlabel(\"Predicted Label\", fontsize=16, labelpad=20)\n","ax.set_ylabel(\"True Label\", fontsize=16, labelpad=20)\n","\n","# Rotasi dan perbesar label sumbu X dan Y\n","plt.xticks(rotation=45, fontsize=12, ha=\"right\")\n","plt.yticks(rotation=0, fontsize=12)\n","\n","# Tampilkan plot\n","plt.tight_layout()  # Sesuaikan tata letak\n","plt.show()\n"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":15,"status":"aborted","timestamp":1733043186348,"user":{"displayName":"Fajar Aulia M247B4KY1372","userId":"14465906709521728749"},"user_tz":-480},"id":"m_pGXdGHHdXa"},"outputs":[],"source":["import os\n","import tensorflow as tf\n","\n","# Define the export directory\n","export_dir = os.path.join(os.getcwd(), WORKING_PATHS['EXPORT'], 'hand-sign-bisindo')  # Change 'bisindo' to your desired model name\n","\n","# Save the model in the SavedModel format\n","tf.saved_model.save(model, export_dir)"]},{"cell_type":"code","execution_count":null,"metadata":{"scrolled":true,"id":"ZeBGBAh5Z0xN","executionInfo":{"status":"aborted","timestamp":1733043186348,"user_tz":-480,"elapsed":15,"user":{"displayName":"Fajar Aulia M247B4KY1372","userId":"14465906709521728749"}}},"outputs":[],"source":["converter = tf.lite.TFLiteConverter.from_saved_model(WORKING_PATHS['EXPORT']) # path to the SavedModel directory\n","tflite_model = converter.convert()\n","\n","# Save the model.\n","with open(os.path.join(WORKING_PATHS['TFLITE'], 'hand-sign-bisindo-model.tflite'), 'wb') as f:\n","  f.write(tflite_model)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Rl5quEEmZ0xN","executionInfo":{"status":"aborted","timestamp":1733043186348,"user_tz":-480,"elapsed":15,"user":{"displayName":"Fajar Aulia M247B4KY1372","userId":"14465906709521728749"}}},"outputs":[],"source":["converter = tf.lite.TFLiteConverter.from_saved_model(WORKING_PATHS['EXPORT'])\n","tflite_model = converter.convert()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"kAGIr9QQZ0xO","executionInfo":{"status":"aborted","timestamp":1733043186349,"user_tz":-480,"elapsed":16,"user":{"displayName":"Fajar Aulia M247B4KY1372","userId":"14465906709521728749"}}},"outputs":[],"source":["import pathlib"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"fbuskwWfZ0xO","executionInfo":{"status":"aborted","timestamp":1733043186349,"user_tz":-480,"elapsed":16,"user":{"displayName":"Fajar Aulia M247B4KY1372","userId":"14465906709521728749"}}},"outputs":[],"source":["tflite_model_file = pathlib.Path('hand-sign-bisindo-model.tflite')\n","tflite_model_file.write_bytes(tflite_model)\n","print(f\"Model disimpan di: {tflite_model_file}\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"0dLCBK89Z0xO","executionInfo":{"status":"aborted","timestamp":1733043186349,"user_tz":-480,"elapsed":15,"user":{"displayName":"Fajar Aulia M247B4KY1372","userId":"14465906709521728749"}}},"outputs":[],"source":["import os\n","import tensorflow as tf\n","\n","# Define the export directory\n","export_dir = os.path.join(os.getcwd(), WORKING_PATHS['EXPORT'], 'hand-sign-bisindo-model.h5')  # Ubah ke nama file yang diinginkan\n","\n","# Save the model in H5 format\n","model.save(export_dir, save_format='h5')\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"kXzXFbP9Z0xO","executionInfo":{"status":"aborted","timestamp":1733043186349,"user_tz":-480,"elapsed":15,"user":{"displayName":"Fajar Aulia M247B4KY1372","userId":"14465906709521728749"}}},"outputs":[],"source":["import os\n","import tensorflow as tf\n","import subprocess\n","\n","# Tentukan direktori kerja dan path model H5\n","export_dir = os.path.join(os.getcwd(), WORKING_PATHS['EXPORT'])\n","h5_model_path = os.path.join(export_dir, 'hand-sign-bisindo-model.h5')\n","\n","# Pastikan model disimpan dalam format H5\n","# model.save(h5_model_path, save_format='h5')\n","# print(f\"Model saved in H5 format at: {h5_model_path}\")\n","\n","output_dir = os.path.join(os.getcwd(), WORKING_PATHS['JSON'])\n","\n","# Tentukan path output untuk model TFJS\n","tfjs_output_dir = os.path.join(output_dir, 'tfjs-hand-sign-bisindo')\n","\n","# Pastikan direktori output ada\n","os.makedirs(tfjs_output_dir, exist_ok=True)\n","\n","# Gunakan tensorflowjs_converter untuk mengonversi model H5 ke format TFJS\n","subprocess.run([\n","    \"tensorflowjs_converter\",\n","    \"--input_format\", \"keras\",\n","    h5_model_path,\n","    tfjs_output_dir\n","])\n","\n","print(f\"Model successfully converted to TFJS format in: {tfjs_output_dir}\")\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Czhc0NeZZ0xP","executionInfo":{"status":"aborted","timestamp":1733043186349,"user_tz":-480,"elapsed":15,"user":{"displayName":"Fajar Aulia M247B4KY1372","userId":"14465906709521728749"}}},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"lQc93UueZ0xP","executionInfo":{"status":"aborted","timestamp":1733043186349,"user_tz":-480,"elapsed":15,"user":{"displayName":"Fajar Aulia M247B4KY1372","userId":"14465906709521728749"}}},"outputs":[],"source":["import tensorflow as tf\n","import numpy as np\n","from io import BytesIO\n","from PIL import Image\n","from IPython.display import display\n","import ipywidgets as widgets\n","\n","# Memuat model TFLite\n","try:\n","    interpreter = tf.lite.Interpreter(model_path=\"hand-sign-bisindo-model.tflite\")\n","    interpreter.allocate_tensors()\n","    print(\"Model berhasil dimuat.\")\n","except Exception as e:\n","    print(f\"Error saat memuat model: {e}\")\n","\n","# Mendapatkan detail input dan output model\n","input_details = interpreter.get_input_details()\n","output_details = interpreter.get_output_details()\n","\n","# Periksa ukuran input model\n","input_shape = input_details[0]['shape']\n","print(f\"Input model shape: {input_shape}\")\n","\n","# Daftar kelas (A-Z)\n","classes = [chr(i) for i in range(ord('A'), ord('Z') + 1)]\n","print(f\"Kelas model: {classes}\")\n","\n","# Membuat widget untuk mengunggah file\n","uploader = widgets.FileUpload(accept=\"image/*\", multiple=True)\n","clear_button = widgets.Button(description=\"Clear Output\", button_style='danger')  # Tombol Clear Output\n","out = widgets.Output()\n","\n","# Tampilkan widget\n","display(widgets.VBox([uploader, clear_button]))\n","display(out)\n","\n","def clear_output_area(_):\n","    \"\"\"Fungsi untuk membersihkan output prediksi.\"\"\"\n","    with out:\n","        out.clear_output()\n","        print(\"Output telah dibersihkan.\")\n","\n","clear_button.on_click(clear_output_area)\n","\n","def file_predict(filename, file, out):\n","    \"\"\"Fungsi untuk memproses gambar, melakukan prediksi, dan menampilkan hasil.\"\"\"\n","    try:\n","        # Memuat dan memproses gambar (ubah ukuran ke dimensi yang sesuai dengan model)\n","        image = tf.keras.utils.load_img(file, target_size=(input_shape[1], input_shape[2]))  # Sesuaikan ukuran\n","        image = tf.keras.utils.img_to_array(image)\n","        image = np.expand_dims(image, axis=0).astype(np.float32)  # Pastikan tipe data float32 sesuai model\n","\n","        # Normalisasi gambar (jika diperlukan)\n","        image = image / 255.0  # Sesuaikan jika model Anda memerlukan normalisasi\n","\n","        # Melakukan inferensi menggunakan model TFLite\n","        interpreter.set_tensor(input_details[0]['index'], image)\n","        interpreter.invoke()\n","        prediction = interpreter.get_tensor(output_details[0]['index'])[0]\n","\n","        with out:\n","            # Menampilkan hasil prediksi\n","            print(f\"\\nFile: {filename}\")\n","            print(f\"Model output: {prediction}\")\n","\n","            # Ambil kelas dengan probabilitas tertinggi\n","            prediction_index = np.argmax(prediction)\n","            predicted_class = classes[prediction_index]\n","            print(f\"Prediksi: {filename} adalah huruf {predicted_class}\")\n","\n","    except Exception as e:\n","        with out:\n","            print(f\"Error saat memproses file {filename}: {e}\")\n","\n","def on_upload_change(change):\n","    \"\"\"Fungsi untuk menangani file yang diunggah dan menjalankan prediksi.\"\"\"\n","    items = change.new\n","    for item in items:\n","        try:\n","            print(f\"Mengunggah file: {item.name}\")\n","            file_jpgdata = BytesIO(item.content)\n","            file_predict(item.name, file_jpgdata, out)\n","        except Exception as e:\n","            print(f\"Error saat menangani file {item.name}: {e}\")\n","\n","# Menghubungkan widget uploader ke fungsi\n","uploader.observe(on_upload_change, names='value')\n","print(\"Widget uploader terhubung. Silakan unggah file gambar.\")\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"BR7lGneDZ0xP","executionInfo":{"status":"aborted","timestamp":1733043186349,"user_tz":-480,"elapsed":15,"user":{"displayName":"Fajar Aulia M247B4KY1372","userId":"14465906709521728749"}}},"outputs":[],"source":[]}],"metadata":{"accelerator":"TPU","colab":{"provenance":[],"gpuType":"V28"},"kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.0"},"metadata":{"interpreter":{"hash":"be80c76d6161546d2d002062bc08897e74314fdf40c3860ac21cd209154864a4"}}},"nbformat":4,"nbformat_minor":0}