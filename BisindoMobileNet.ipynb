{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Library And Setup Folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 2079,
     "status": "ok",
     "timestamp": 1622576910951,
     "user": {
      "displayName": "Juan Anthonius Kusjadi M2322241",
      "photoUrl": "",
      "userId": "12901569846707157398"
     },
     "user_tz": -420
    },
    "id": "ax5doCT4HdXK"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import gdown\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from matplotlib import gridspec\n",
    "from matplotlib.patches import Rectangle\n",
    "from tensorflow.keras.callbacks import Callback\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
    "from tensorflow.keras import regularizers\n",
    "# from tensorflow.keras.applications import MobileNetV3Large\n",
    "from tensorflow.keras.applications import MobileNetV2\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras import Model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras.preprocessing import image\n",
    "from tensorflow.keras.applications.mobilenet_v2 import preprocess_input\n",
    "from tensorflow.keras.models import load_model\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import seaborn as sn\n",
    "import pandas as pd\n",
    "import pathlib\n",
    "import subprocess\n",
    "from io import BytesIO\n",
    "from PIL import Image\n",
    "from IPython.display import display\n",
    "import ipywidgets as widgets\n",
    "import math\n",
    "\n",
    "INPUT_SIZE = (224, 224)\n",
    "\n",
    "WORKING_PATHS = {\n",
    "    'BASE': os.path.join('development'),\n",
    "    'DATASET': os.path.join('development', 'dataset'),\n",
    "    'TRAIN_DATASET': os.path.join('development', 'dataset', 'train'),\n",
    "    'TEST_DATASET': os.path.join('development', 'dataset', 'test'),\n",
    "    'VALID_DATASET': os.path.join('development', 'dataset', 'val'),\n",
    "    'OUTPUT': os.path.join('development', 'output'), \n",
    "    'EXPORT': os.path.join('development', 'output', 'my-model', 'export', 'BISINDO'), \n",
    "    'TFLITE':os.path.join('development', 'output', 'my-model', 'tflite'), \n",
    " }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "executionInfo": {
     "elapsed": 1400,
     "status": "ok",
     "timestamp": 1622576917796,
     "user": {
      "displayName": "Juan Anthonius Kusjadi M2322241",
      "photoUrl": "",
      "userId": "12901569846707157398"
     },
     "user_tz": -420
    },
    "id": "vdR-O4UTHdXL"
   },
   "outputs": [],
   "source": [
    "# Create working dirs\n",
    "for path in WORKING_PATHS.values():\n",
    "    if not os.path.exists(path):\n",
    "        if os.name == 'posix':\n",
    "            !mkdir -p {path}\n",
    "        if os.name == 'nt':\n",
    "            !mkdir {path}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Argumentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import cv2\n",
    "import numpy as np\n",
    "from PIL import Image, ImageEnhance\n",
    "import imutils\n",
    "\n",
    "# Target jumlah data per kelas\n",
    "TARGET_SIZE = 10000\n",
    "FINAL_SIZE = (224, 224)\n",
    "IMG_SIZE = (224, 224)\n",
    "AUGMENTATION_FOLDERS = [\"resize\", \"brightness\", \"translate\", \"zoom\", \"rotate\"]\n",
    "\n",
    "# Fungsi untuk augmentasi satu gambar\n",
    "def augment_image(image, folder, index):\n",
    "    augmented_images = []\n",
    "\n",
    "    # Resize\n",
    "    resized_image = cv2.resize(image, FINAL_SIZE)\n",
    "    augmented_images.append(resized_image)\n",
    "\n",
    "    # Brightness\n",
    "    pil_image = Image.fromarray(cv2.cvtColor(image, cv2.COLOR_BGR2RGB))\n",
    "    enhancer = ImageEnhance.Brightness(pil_image)\n",
    "    for factor in [0.75, 1.0, 1.25, 1.5]:\n",
    "        bright_img = enhancer.enhance(factor)\n",
    "        augmented_images.append(cv2.cvtColor(np.array(bright_img), cv2.COLOR_RGB2BGR))\n",
    "\n",
    "    # Translate\n",
    "    for x_shift in range(-10, 11, 5):\n",
    "        for y_shift in range(-10, 11, 5):\n",
    "            M = np.float32([[1, 0, x_shift], [0, 1, y_shift]])\n",
    "            translated = cv2.warpAffine(image, M, IMG_SIZE)\n",
    "            translated = cv2.resize(translated, FINAL_SIZE)\n",
    "            augmented_images.append(translated)\n",
    "\n",
    "    # Zoom\n",
    "    for scale in [12, 24, 36]:\n",
    "        zoom_crop = image[scale:-scale, scale:-scale]\n",
    "        zoom_resized = cv2.resize(zoom_crop, FINAL_SIZE)\n",
    "        augmented_images.append(zoom_resized)\n",
    "\n",
    "    # Rotate\n",
    "    for angle in range(-45, 50, 10):\n",
    "        rotated = imutils.rotate_bound(image, angle)\n",
    "        rotated = cv2.resize(rotated, FINAL_SIZE)\n",
    "        augmented_images.append(rotated)\n",
    "\n",
    "    return augmented_images\n",
    "\n",
    "# Proses setiap folder\n",
    "for folder in sorted(os.listdir(datasets_dir)):\n",
    "    folder_path = os.path.join(datasets_dir, folder)\n",
    "    print(f\"Processing folder: {folder} (Original images: {len(os.listdir(folder_path))})\")\n",
    "\n",
    "    # Buat folder target\n",
    "    output_dir = os.path.join(\"./kurang\", folder)\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "    # Ambil semua gambar asli\n",
    "    original_images = sorted(os.listdir(folder_path))\n",
    "    num_original = len(original_images)\n",
    "\n",
    "    # Jika gambar asli >= TARGET_SIZE, pilih secara acak hingga jumlahnya pas\n",
    "    if num_original >= TARGET_SIZE:\n",
    "        selected_images = random.sample(original_images, TARGET_SIZE)\n",
    "        for i, image_name in enumerate(selected_images):\n",
    "            image_path = os.path.join(folder_path, image_name)\n",
    "            image = cv2.imread(image_path)\n",
    "            image = cv2.resize(image, FINAL_SIZE)\n",
    "            output_path = os.path.join(output_dir, f\"{folder}_img_{i:05d}.jpg\")\n",
    "            cv2.imwrite(output_path, image)\n",
    "    else:\n",
    "        # Augmentasi diperlukan\n",
    "        total_augmented = 0\n",
    "        augmentations_needed = TARGET_SIZE - num_original\n",
    "\n",
    "        for i, image_name in enumerate(original_images):\n",
    "            image_path = os.path.join(folder_path, image_name)\n",
    "            image = cv2.imread(image_path)\n",
    "            image = cv2.resize(image, IMG_SIZE)\n",
    "\n",
    "            # Augment gambar ini\n",
    "            augmented_images = augment_image(image, folder, i)\n",
    "            for aug_image in augmented_images:\n",
    "                if total_augmented >= augmentations_needed:\n",
    "                    break\n",
    "                output_path = os.path.join(output_dir, f\"{folder}_img_{total_augmented:05d}.jpg\")\n",
    "                cv2.imwrite(output_path, aug_image)\n",
    "                total_augmented += 1\n",
    "\n",
    "            if total_augmented >= augmentations_needed:\n",
    "                break\n",
    "\n",
    "        # Tambahkan gambar asli ke folder target\n",
    "        for i, image_name in enumerate(original_images):\n",
    "            image_path = os.path.join(folder_path, image_name)\n",
    "            image = cv2.imread(image_path)\n",
    "            image = cv2.resize(image, FINAL_SIZE)\n",
    "            output_path = os.path.join(output_dir, f\"{folder}_img_{total_augmented + i:05d}.jpg\")\n",
    "            cv2.imwrite(output_path, image)\n",
    "\n",
    "    print(f\"Total images for folder {folder}: {TARGET_SIZE}\")\n",
    "\n",
    "print(\"Augmentation completed!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Training labels:\", os.listdir(WORKING_PATHS['TRAIN_DATASET']))\n",
    "print(\"Validation labels:\", os.listdir(WORKING_PATHS['VALID_DATASET']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualisasi Jumlah data dan Sampel Gamabar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 324
    },
    "executionInfo": {
     "elapsed": 814,
     "status": "ok",
     "timestamp": 1622576938272,
     "user": {
      "displayName": "Juan Anthonius Kusjadi M2322241",
      "photoUrl": "",
      "userId": "12901569846707157398"
     },
     "user_tz": -420
    },
    "id": "4FxtA-Q0HdXO",
    "outputId": "879f38ad-6c66-4330-a0a3-0ac5b1022726"
   },
   "outputs": [],
   "source": [
    "list_label = os.listdir(WORKING_PATHS['TRAIN_DATASET'])\n",
    "\n",
    "train_data_count = {label: 0 for label in list_label}\n",
    "test_data_count = {label: 0 for label in list_label}\n",
    "TRAIN_IMG_MIN = float('inf')\n",
    "\n",
    "for label in list_label:\n",
    "    train_label_path = os.path.join(WORKING_PATHS['TRAIN_DATASET'], label)\n",
    "    test_label_path = os.path.join(WORKING_PATHS['VALID_DATASET'], label)\n",
    "\n",
    "    train_data_count[label] = len(os.listdir(train_label_path))\n",
    "    test_data_count[label] = len(os.listdir(test_label_path))\n",
    "\n",
    "    TRAIN_IMG_MIN = min(TRAIN_IMG_MIN, train_data_count[label])\n",
    "\n",
    "y_positions = np.arange(len(list_label))\n",
    "train_counts = list(train_data_count.values())\n",
    "test_counts = list(test_data_count.values())\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(18, 6))\n",
    "fig.suptitle('Training and Validation Data Distribution', fontsize=16)\n",
    "\n",
    "axes[0].bar(y_positions, train_counts, alpha=0.7, color='blue', width=0.6)\n",
    "axes[0].set_xticks(y_positions)\n",
    "axes[0].set_xticklabels(list_label, fontsize=12)\n",
    "axes[0].set_title('Training Data', fontsize=14)\n",
    "axes[0].set_ylabel('Number of Images', fontsize=12)\n",
    "axes[0].set_xlabel('Labels', fontsize=12)\n",
    "\n",
    "axes[1].bar(y_positions, test_counts, alpha=0.7, color='orange', width=0.6)\n",
    "axes[1].set_xticks(y_positions)\n",
    "axes[1].set_xticklabels(list_label, fontsize=12)\n",
    "axes[1].set_title('Validation Data', fontsize=14)\n",
    "axes[1].set_ylabel('Number of Images', fontsize=12)\n",
    "axes[1].set_xlabel('Labels', fontsize=12)\n",
    "\n",
    "plt.subplots_adjust(wspace=0.4)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "executionInfo": {
     "elapsed": 6493,
     "status": "ok",
     "timestamp": 1622576951631,
     "user": {
      "displayName": "Juan Anthonius Kusjadi M2322241",
      "photoUrl": "",
      "userId": "12901569846707157398"
     },
     "user_tz": -420
    },
    "id": "frX9kErIHdXR",
    "outputId": "88c647da-637f-41c1-8b06-4e9fda432fcf",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "seed = random.randint(0, TRAIN_IMG_MIN)\n",
    "\n",
    "columns = 3\n",
    "rows = math.ceil(len(list_label) / columns)\n",
    "\n",
    "figure_size = 4\n",
    "fig = plt.figure(figsize=(figure_size * columns, figure_size * rows))\n",
    "fig.suptitle('Randomly Selected Training Preview', fontsize=20, fontweight='bold', y=0.98)\n",
    "\n",
    "grid = gridspec.GridSpec(rows, columns, wspace=0.5, hspace=0.8)\n",
    "\n",
    "for idx, label in enumerate(list_label):\n",
    "    label_dir = os.path.join(WORKING_PATHS['TRAIN_DATASET'], label)\n",
    "    random_image = random.choice(os.listdir(label_dir))\n",
    "    image_path = os.path.join(label_dir, random_image)\n",
    "    \n",
    "    img = image.load_img(image_path)\n",
    "    img_resized = img.resize(INPUT_SIZE)\n",
    "\n",
    "    ax = fig.add_subplot(grid[idx])\n",
    "    ax.imshow(img_resized)\n",
    "    ax.set_title(label, fontsize=12, fontweight='medium', color='navy')\n",
    "    ax.axis('off')\n",
    "\n",
    "    frame_color = 'black'\n",
    "    border_thickness = 2\n",
    "    ax.add_patch(Rectangle(\n",
    "        (0, 0), INPUT_SIZE[0], INPUT_SIZE[1],\n",
    "        linewidth=border_thickness,\n",
    "        edgecolor=frame_color,\n",
    "        facecolor='none'\n",
    "    ))\n",
    "\n",
    "plt.subplots_adjust(top=0.92, left=0.05, right=0.95, bottom=0.05)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1219,
     "status": "ok",
     "timestamp": 1622576962384,
     "user": {
      "displayName": "Juan Anthonius Kusjadi M2322241",
      "photoUrl": "",
      "userId": "12901569846707157398"
     },
     "user_tz": -420
    },
    "id": "Nb4pJP2jHdXS",
    "outputId": "1eb1faa3-2f0b-422f-88ee-ecd090db26f9"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rescale = 1 / 255,\n",
    "    fill_mode = 'nearest'\n",
    ")\n",
    "validation_datagen = ImageDataGenerator(rescale = 1 / 255)\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    WORKING_PATHS['TRAIN_DATASET'],\n",
    "    target_size = INPUT_SIZE,\n",
    "    class_mode = 'categorical'\n",
    ")\n",
    "validation_generator = validation_datagen.flow_from_directory(\n",
    "    WORKING_PATHS['VALID_DATASET'],\n",
    "    target_size = INPUT_SIZE,\n",
    "    class_mode = 'categorical'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 328,
     "status": "ok",
     "timestamp": 1622576971642,
     "user": {
      "displayName": "Juan Anthonius Kusjadi M2322241",
      "photoUrl": "",
      "userId": "12901569846707157398"
     },
     "user_tz": -420
    },
    "id": "2RiHeezWHdXT",
    "outputId": "5eb745a0-3966-4369-f72a-832e0f8a4d47"
   },
   "outputs": [],
   "source": [
    "LABELS = list(train_generator.class_indices.keys())\n",
    "NUM_CLASSES = len(LABELS)\n",
    "print(NUM_CLASSES)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Pre Train Model dan Fine Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1570,
     "status": "ok",
     "timestamp": 1622576979109,
     "user": {
      "displayName": "Juan Anthonius Kusjadi M2322241",
      "photoUrl": "",
      "userId": "12901569846707157398"
     },
     "user_tz": -420
    },
    "id": "aqQJlHx1HdXU",
    "outputId": "36ba5bc2-2ee3-4ef2-acf3-dbd8010dcefe"
   },
   "outputs": [],
   "source": [
    "pre_trained_model = MobileNetV2(\n",
    "    weights = 'imagenet', \n",
    "    input_shape = (INPUT_SIZE[0], INPUT_SIZE[1], 3), \n",
    "    include_top = False, \n",
    ")\n",
    "\n",
    "pre_trained_model.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "executionInfo": {
     "elapsed": 359,
     "status": "ok",
     "timestamp": 1622576981751,
     "user": {
      "displayName": "Juan Anthonius Kusjadi M2322241",
      "photoUrl": "",
      "userId": "12901569846707157398"
     },
     "user_tz": -420
    },
    "id": "jWtg5P8wHdXV",
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Fine Tuning\n",
    "pre_trained_model.trainable = True\n",
    "\n",
    "for layer in pre_trained_model.layers[:100]:\n",
    "    layer.trainable = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bulid Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 2526106,
     "status": "ok",
     "timestamp": 1622579510074,
     "user": {
      "displayName": "Juan Anthonius Kusjadi M2322241",
      "photoUrl": "",
      "userId": "12901569846707157398"
     },
     "user_tz": -420
    },
    "id": "dUAQjPtFHdXW",
    "outputId": "8d74e25e-3282-40b5-8c2b-92aeef48b575",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# x = layers.Flatten()(pre_trained_model.output)\n",
    "x = layers.Dropout(0.3)(pre_trained_model.output)\n",
    "x = layers.Flatten()(x)\n",
    "x = layers.Dense(512, activation='relu', kernel_regularizer=regularizers.l2(0.01))(x)\n",
    "x = layers.Dropout(0.6)(x)\n",
    "x = layers.Dense(NUM_CLASSES, activation='softmax')(x) \n",
    "\n",
    "model = Model(inputs = pre_trained_model.input, outputs = x)\n",
    "\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Membuat Callback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomCallback(Callback):\n",
    "    def __init__(self, target_accuracy=0.9, max_val_loss=0.2):\n",
    "        super().__init__()\n",
    "        self.target_accuracy = target_accuracy\n",
    "        self.max_val_loss = max_val_loss\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        # Memeriksa apakah accuracy >= 0.95 dan validation loss <= 0.1\n",
    "        val_loss = logs.get('val_loss')\n",
    "        accuracy = logs.get('accuracy')\n",
    "\n",
    "        if accuracy >= self.target_accuracy and val_loss <= self.max_val_loss:\n",
    "            print(f\"\\nEpoch {epoch+1}: Accuracy is {accuracy:.4f} and validation loss is {val_loss:.4f}. Stopping training.\")\n",
    "            self.model.stop_training = True  # Menghentikan pelatihan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "early_stopping = EarlyStopping(\n",
    "    monitor='val_loss', \n",
    "    patience=3, \n",
    "    restore_best_weights=True\n",
    ")\n",
    "\n",
    "custom_callback = CustomCallback(target_accuracy=0.95, max_val_loss=0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(\n",
    "    optimizer = Adam(learning_rate=0.0001),\n",
    "    loss = 'categorical_crossentropy', \n",
    "    metrics = ['accuracy']\n",
    ")\n",
    "\n",
    "history = model.fit(\n",
    "    train_generator, \n",
    "    validation_data = validation_generator, \n",
    "    epochs = 10, \n",
    "    # validation_steps = 5,\n",
    "    callbacks=[early_stopping, custom_callback],\n",
    "    verbose = 1,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 417
    },
    "executionInfo": {
     "elapsed": 1255,
     "status": "ok",
     "timestamp": 1622579624970,
     "user": {
      "displayName": "Juan Anthonius Kusjadi M2322241",
      "photoUrl": "",
      "userId": "12901569846707157398"
     },
     "user_tz": -420
    },
    "id": "obqKc1Z3HdXW",
    "outputId": "0fd433d3-21e7-4df9-f4e4-39e1194a3d6e"
   },
   "outputs": [],
   "source": [
    "acc = history.history['accuracy']\n",
    "val_acc = history.history['val_accuracy']\n",
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "\n",
    "epochs = range(len(acc))\n",
    "\n",
    "fig, axs = plt.subplots(2, 1, figsize = (5, 6))\n",
    "fig.suptitle('Training and Validation plotting')\n",
    "axs[0].plot(epochs, acc, 'r', label = 'Training accuracy')\n",
    "axs[0].plot(epochs, val_acc, 'b', label = 'Validation accuracy')\n",
    "axs[0].set_title('Training')\n",
    "axs[0].legend()\n",
    "axs[1].plot(epochs, loss, 'r', label = 'Training Loss')\n",
    "axs[1].plot(epochs, val_loss, 'b', label = 'Validation Loss')\n",
    "axs[1].set_title('Loss')\n",
    "axs[1].legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluasi Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "test_datagen = ImageDataGenerator(rescale=1.0 / 255)\n",
    "\n",
    "test_generator = test_datagen.flow_from_directory(\n",
    "    WORKING_PATHS['TEST_DATASET'],\n",
    "    target_size=(224, 224),\n",
    "    batch_size=32,\n",
    "    class_mode='categorical',\n",
    "    shuffle=False\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = model.evaluate(test_generator, verbose=1)  # Atau test_dataset\n",
    "print(f\"Loss: {results[0]:.4f}, Accuracy: {results[1]:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "executionInfo": {
     "elapsed": 279,
     "status": "ok",
     "timestamp": 1622580496647,
     "user": {
      "displayName": "Juan Anthonius Kusjadi M2322241",
      "photoUrl": "",
      "userId": "12901569846707157398"
     },
     "user_tz": -420
    },
    "id": "H7M2pWeMHdXY"
   },
   "outputs": [],
   "source": [
    "def selectRandomImage(labels = None):\n",
    "    if labels == None:\n",
    "        seed = random.randint(1, NUM_CLASSES)\n",
    "        label_seed = LABELS[seed - 1]\n",
    "    else:\n",
    "        seed = random.randint(1, len(labels))\n",
    "        label_seed = labels[seed - 1]\n",
    "    \n",
    "    path = os.path.join(WORKING_PATHS['TEST_DATASET'], label_seed)\n",
    "    test_dir = os.listdir(path)\n",
    "    test_dir_num = len(test_dir)\n",
    "    file_name = os.listdir(path)[random.randint(0, test_dir_num - 1)]\n",
    "    return (os.path.join(path, file_name), file_name, label_seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "executionInfo": {
     "elapsed": 2,
     "status": "ok",
     "timestamp": 1622580453751,
     "user": {
      "displayName": "Juan Anthonius Kusjadi M2322241",
      "photoUrl": "",
      "userId": "12901569846707157398"
     },
     "user_tz": -420
    },
    "id": "PKmvLw4HHdXY"
   },
   "outputs": [],
   "source": [
    "def create_result_plot(prediction_list, prediction_label, actual_label, file_name, img):\n",
    "    # Create figure and axes\n",
    "    fig = plt.figure(figsize=(12, 6))\n",
    "    grid = fig.add_gridspec(1, 2, wspace=0.4)\n",
    "    fig.suptitle(f'Image \"{file_name}\" Predicted as: {prediction_label}', fontsize=16, fontweight='bold', y=1.02)\n",
    "\n",
    "    # Set background color based on prediction correctness (softer colors)\n",
    "    bg_color = '#C6E2FF' if prediction_label == actual_label else '#F5B7B1'  # Light blue for correct, soft red for incorrect\n",
    "    fig.patch.set_facecolor(bg_color)\n",
    "\n",
    "    # Plot actual image with title\n",
    "    ax1 = fig.add_subplot(grid[0, 0])\n",
    "    ax1.imshow(img)\n",
    "    ax1.axis('off')  # Hide axes for a cleaner appearance\n",
    "    ax1.set_title(f'Actual: {actual_label}', fontsize=14, color='midnightblue', fontweight='medium')\n",
    "\n",
    "    # Plot prediction probabilities\n",
    "    ax2 = fig.add_subplot(grid[0, 1])\n",
    "    ax2.bar(range(len(prediction_list)), prediction_list, color='#A9D0F5', edgecolor='#AED6F1')  # Soft pastel blue\n",
    "    ax2.set_title('Class Probabilities', fontsize=14, fontweight='medium')\n",
    "    ax2.set_ylabel('Probability', fontsize=12)\n",
    "    ax2.set_xlabel('Classes', fontsize=12)\n",
    "    ax2.set_xticks(range(len(prediction_list)))\n",
    "    ax2.set_xticklabels(LABELS, rotation=45, fontsize=10)  # Rotate for better visibility\n",
    "\n",
    "    # Enhance layout\n",
    "    plt.subplots_adjust(top=0.85, bottom=0.2, left=0.1, right=0.95)\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 381
    },
    "executionInfo": {
     "elapsed": 1524,
     "status": "ok",
     "timestamp": 1622580865853,
     "user": {
      "displayName": "Juan Anthonius Kusjadi M2322241",
      "photoUrl": "",
      "userId": "12901569846707157398"
     },
     "user_tz": -420
    },
    "id": "hP_4XA4VHdXZ",
    "outputId": "430a7983-78df-4eb6-a429-3d8d6995d9b0"
   },
   "outputs": [],
   "source": [
    "# file_path, file_name, label = selectRandomImage()\n",
    "file_path, file_name, label = selectRandomImage(['N'])\n",
    "img = image.load_img(file_path, target_size = INPUT_SIZE)\n",
    "x = image.img_to_array(img)\n",
    "x = np.expand_dims(x, axis = 0)\n",
    "x = preprocess_input(x)\n",
    "\n",
    "prediction = model.predict(x, batch_size = 10)\n",
    "index = int(prediction[0].argmax(axis = -1))\n",
    "\n",
    "create_result_plot(prediction[0].reshape(NUM_CLASSES), LABELS[index], label, file_name, img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "WWebegTyHdXZ",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "MAX_FILES_PER_LABEL = 100\n",
    "\n",
    "y_true = []\n",
    "y_pred = []\n",
    "\n",
    "for label in LABELS:\n",
    "    path = os.path.join(WORKING_PATHS['TEST_DATASET'], label)\n",
    "    files = os.listdir(path)[:MAX_FILES_PER_LABEL]\n",
    "    \n",
    "    for file_name in files:\n",
    "        file_loc = os.path.join(path, file_name)\n",
    "        \n",
    "        img = image.load_img(file_loc, target_size=INPUT_SIZE)\n",
    "        x = preprocess_input(np.expand_dims(image.img_to_array(img), axis=0))\n",
    "\n",
    "        \n",
    "        index = model.predict(x, batch_size=1).argmax(axis=-1)[0]\n",
    "        y_true.append(label)\n",
    "        y_pred.append(LABELS[index])\n",
    "\n",
    "mat = confusion_matrix(y_true, y_pred, labels=LABELS)\n",
    "mat_norm = mat / mat.sum(axis=1, keepdims=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cm = pd.DataFrame(mat_norm, index=LABELS, columns=LABELS)\n",
    "\n",
    "plt.figure(figsize=(20, 15))\n",
    "ax = sn.heatmap(\n",
    "    df_cm,\n",
    "    annot=True,\n",
    "    fmt=\".2f\",\n",
    "    cmap=\"coolwarm\",\n",
    "    annot_kws={\"size\": 10},\n",
    "    linewidths=0.5,\n",
    "    linecolor=\"black\"\n",
    ")\n",
    "\n",
    "\n",
    "ax.set_title(\"Test Confusion Matrix\", fontsize=20, pad=20)\n",
    "ax.set_xlabel(\"Predicted Label\", fontsize=16, labelpad=20)\n",
    "ax.set_ylabel(\"True Label\", fontsize=16, labelpad=20)\n",
    "\n",
    "\n",
    "plt.xticks(rotation=45, fontsize=12, ha=\"right\")\n",
    "plt.yticks(rotation=0, fontsize=12)\n",
    "\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# Generate classification report\n",
    "report = classification_report(y_true, y_pred, target_names=LABELS)\n",
    "\n",
    "print(report)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save Model dan Convert TFLITE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1913,
     "status": "ok",
     "timestamp": 1622580994820,
     "user": {
      "displayName": "Juan Anthonius Kusjadi M2322241",
      "photoUrl": "",
      "userId": "12901569846707157398"
     },
     "user_tz": -420
    },
    "id": "m_pGXdGHHdXa",
    "outputId": "c9086c9e-ca79-4af3-a618-9ece7d3616b2"
   },
   "outputs": [],
   "source": [
    "# Define the export directory\n",
    "export_dir = os.path.join(os.getcwd(), WORKING_PATHS['EXPORT'], 'BISINDO')  # Change 'bisindo' to your desired model name\n",
    "\n",
    "# Save the model in the SavedModel format\n",
    "tf.saved_model.save(model, export_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "converter = tf.lite.TFLiteConverter.from_saved_model(WORKING_PATHS['EXPORT'])\n",
    "tflite_model = converter.convert()\n",
    "\n",
    "# Save the model.\n",
    "with open(os.path.join(WORKING_PATHS['TFLITE'], 'mobilenetv2-bisindo-model.tflite'), 'wb') as f:\n",
    "  f.write(tflite_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "converter = tf.lite.TFLiteConverter.from_saved_model(WORKING_PATHS['EXPORT'])\n",
    "tflite_model = converter.convert()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tflite_model_file = pathlib.Path('mobilenetv2-bisindo-model.tflite.tflite')\n",
    "tflite_model_file.write_bytes(tflite_model)\n",
    "print(f\"Model disimpan di: {tflite_model_file}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "model = tf.keras.models.load_model(r\"C:\\bahasa-isyarat\\Bangkit-Capstone\\development\\output\\my-model\\export\\BISINDO\\mobilenetv2-bisindo-model.tflite.h5\")\n",
    "converter = tf.lite.TFLiteConverter.from_keras_model(model)\n",
    "tflite_model = converter.convert()\n",
    "open(\"coba.tflite\", \"wb\").write(tflite_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "# Muat model dari file .h5\n",
    "h5_model_path = r\"C:\\bahasa-isyarat\\Bangkit-Capstone\\development\\output\\my-model\\export\\BISINDO\\mobilenetv2-bisindo-model.tflite.h5\"\n",
    "model = tf.keras.models.load_model(h5_model_path)\n",
    "\n",
    "# Konversi model ke format TensorFlow Lite\n",
    "converter = tf.lite.TFLiteConverter.from_keras_model(model)\n",
    "tflite_model = converter.convert()\n",
    "\n",
    "# Simpan model .tflite\n",
    "tflite_model_path = r\"C:\\bahasa-isyarat\\Bangkit-Capstone\\model\\coba.tflite\"\n",
    "with open(tflite_model_path, \"wb\") as f:\n",
    "    f.write(tflite_model)\n",
    "\n",
    "print(\"Model berhasil dikonversi ke format TFLite.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the export directory\n",
    "export_dir = os.path.join(os.getcwd(), WORKING_PATHS['EXPORT'], 'mobilenetv2-bisindo-model.h5')  # Ubah ke nama file yang diinginkan\n",
    "\n",
    "# Save the model in H5 format\n",
    "model.save(export_dir, save_format='h5')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import ipywidgets as widgets\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from io import BytesIO\n",
    "from IPython.display import display\n",
    "\n",
    "# Inisialisasi penghitung prediksi benar dan salah\n",
    "correct_predictions = 0\n",
    "incorrect_predictions = 0\n",
    "\n",
    "# Memuat model TFLite\n",
    "try:\n",
    "    interpreter = tf.lite.Interpreter(model_path=\"mobilenetv2-bisindo-model.tflite\")\n",
    "    interpreter.allocate_tensors()\n",
    "    print(\"Model berhasil dimuat.\")\n",
    "except Exception as e:\n",
    "    print(f\"Error saat memuat model: {e}\")\n",
    "\n",
    "# Mendapatkan detail input dan output model\n",
    "input_details = interpreter.get_input_details()\n",
    "output_details = interpreter.get_output_details()\n",
    "\n",
    "# Periksa ukuran input model\n",
    "input_shape = input_details[0]['shape']\n",
    "print(f\"Input model shape: {input_shape}\")\n",
    "\n",
    "# Daftar kelas (A-Z)\n",
    "classes = [chr(i) for i in range(ord('A'), ord('Z') + 1)]\n",
    "print(f\"Kelas model: {classes}\")\n",
    "\n",
    "# Membuat widget untuk mengunggah file\n",
    "uploader = widgets.FileUpload(accept=\"image/*\", multiple=True)\n",
    "clear_button = widgets.Button(description=\"Clear Output\", button_style='danger')  # Tombol Clear Output\n",
    "out = widgets.Output()\n",
    "\n",
    "# Menampilkan widget\n",
    "box = widgets.VBox([uploader, clear_button, out])\n",
    "display(box)\n",
    "\n",
    "def clear_output_area(_):\n",
    "    \"\"\"Fungsi untuk membersihkan output prediksi.\"\"\"\n",
    "    global correct_predictions, incorrect_predictions\n",
    "    with out:\n",
    "        out.clear_output()\n",
    "        correct_predictions = 0\n",
    "        incorrect_predictions = 0\n",
    "        print(\"Output telah dibersihkan.\")\n",
    "        print(f\"Jumlah prediksi benar: {correct_predictions}\")\n",
    "        print(f\"Jumlah prediksi salah: {incorrect_predictions}\")\n",
    "\n",
    "clear_button.on_click(clear_output_area)\n",
    "\n",
    "def preprocess_image(file, target_shape):\n",
    "    \"\"\"Fungsi untuk memuat dan memproses gambar agar sesuai dengan input model.\"\"\"\n",
    "    try:\n",
    "        # Memuat gambar\n",
    "        image = tf.image.decode_image(file.read(), channels=3)\n",
    "        # Ubah ukuran gambar sesuai target\n",
    "        image = tf.image.resize(image, (target_shape[1], target_shape[2]))\n",
    "        # Normalisasi gambar ke rentang [0, 1]\n",
    "        image = image / 255.0\n",
    "        # Tambahkan dimensi batch\n",
    "        image = np.expand_dims(image, axis=0).astype(np.float32)\n",
    "        return image\n",
    "    except Exception as e:\n",
    "        print(f\"Error saat memproses gambar: {e}\")\n",
    "        return None\n",
    "\n",
    "def file_predict(filename, file, out):\n",
    "    global correct_predictions, incorrect_predictions  # Akses variabel global\n",
    "\n",
    "    try:\n",
    "        # Preproses gambar\n",
    "        image = preprocess_image(file, input_shape)\n",
    "        if image is None:\n",
    "            raise ValueError(\"Gagal memproses gambar.\")\n",
    "\n",
    "        # Melakukan inferensi menggunakan model TFLite\n",
    "        interpreter.set_tensor(input_details[0]['index'], image)\n",
    "        interpreter.invoke()\n",
    "        prediction = interpreter.get_tensor(output_details[0]['index'])[0]\n",
    "\n",
    "        with out:\n",
    "            # Menampilkan hasil prediksi\n",
    "            print(f\"\\nFile: {filename}\")\n",
    "            print(f\"Model output: {prediction}\")\n",
    "\n",
    "            # Ambil kelas dengan probabilitas tertinggi\n",
    "            prediction_index = np.argmax(prediction)\n",
    "            predicted_class = classes[prediction_index]\n",
    "            print(f\"Prediksi: {filename} adalah huruf {predicted_class}\")\n",
    "\n",
    "            # Ekstrak label huruf dari nama file (misalnya 'Huruf-B-36.jpg' -> 'B')\n",
    "            true_class = filename.split('-')[1]  # Ambil huruf dari nama file (misalnya 'Huruf-B-36' -> 'B')\n",
    "            if predicted_class == true_class:\n",
    "                correct_predictions += 1\n",
    "                print(f\"Prediksi benar!\")\n",
    "            else:\n",
    "                incorrect_predictions += 1\n",
    "                print(f\"Prediksi salah! Seharusnya: {true_class}\")\n",
    "\n",
    "            # Tampilkan jumlah prediksi yang benar dan salah\n",
    "            print(f\"\\nJumlah prediksi benar: {correct_predictions}\")\n",
    "            print(f\"Jumlah prediksi salah: {incorrect_predictions}\")\n",
    "\n",
    "    except Exception as e:\n",
    "        with out:\n",
    "            print(f\"Error saat memproses file {filename}: {e}\")\n",
    "\n",
    "def on_upload_change(change):\n",
    "    \"\"\"Fungsi untuk menangani file yang diunggah dan menjalankan prediksi.\"\"\"\n",
    "    items = change.new\n",
    "    for item in items:\n",
    "        try:\n",
    "            print(f\"Mengunggah file: {item.name}\")\n",
    "            file_jpgdata = BytesIO(item.content)\n",
    "            file_predict(item.name, file_jpgdata, out)\n",
    "        except Exception as e:\n",
    "            print(f\"Error saat menangani file {item.name}: {e}\")\n",
    "\n",
    "# Menghubungkan widget uploader ke fungsi\n",
    "uploader.observe(on_upload_change, names='value')\n",
    "print(\"Widget uploader terhubung. Silakan unggah file gambar.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "TPU",
  "colab": {
   "name": "handSignGestureMobileNet.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  },
  "metadata": {
   "interpreter": {
    "hash": "be80c76d6161546d2d002062bc08897e74314fdf40c3860ac21cd209154864a4"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
